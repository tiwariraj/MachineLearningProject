output_file = file,
word_document(),
# pdf_document(),
# html_document(),
params = params,
envir = new.env(parent = globalenv())
)
}
)
packages <- c("shiny", "shinydashboard", "sqldf", "plotly", "DT", "haven", "purrr", "labelled", "rjson", "rmarkdown", "knitr", "tidyr", "car", "FSA", "lme4", "sas7bdat", "dplyr")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
})
source('global.R', local=TRUE)
search()
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
goods=goods %>%
filter(MarketName=="Atlanta, GA")
goods
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
goods
unique(x$Classification)
goods <- fread(file = "goods.csv")
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
goods
goods %>% filter(MarketName,Classification,MonthlyCost) %>%
summarise(
AvgCityTypeCost = mean(MonthlyCost,na.rm =TRUE),
Index = (MonthlyCost/mean(MonthlyCost,na.rm =TRUE)*100))
goods %>%
summarise(
AvgCityTypeCost = mean(MonthlyCost,na.rm =TRUE),
Index = (MonthlyCost/mean(MonthlyCost,na.rm =TRUE)*100))
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
shiny::runApp('~/R/Code/IRR Data Science Build/Shiny Apps/flights_final')
shiny::runApp('~/R/Code/IRR Data Science Build/Shiny Apps/CostofLivingProject')
library(ISLR)
head(OJ)
head(OJ)
str(OJ)
attach(OJ)
hist(OJ)
summary(Purchase)
hist(Purchase)
createDataPartition(OJ, p = .8,
list = FALSE,
times = 1)
library(caret)
createDataPartition(OJ, p = .8,
list = FALSE,
times = 1)
train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
head(train)
train
head(OJ)
train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.test = OJ[-train, ] #Test dataset.
Purchase.test = Purchase[-train] #Test response.
tree.Purchase = tree(Purchase ~ ., split = "gini", data = Carseats, subset = train)
library(tree)
tree.Purchase = tree(Purchase ~ ., split = "gini", data = Carseats, subset = train)
tree.Purchase = tree(Purchase ~ ., split = "gini", data = OJ[train, ])
summary(tree.Purchase)
plot(tree.Purchase)
text(tree.Purchase, pretty = 0) #Yields category names instead of dummy variables.
tree.Purchase
View(OJ.test)
tree.pred = predict(tree.Purchase, OJ.test, type = "class")
tree.pred
table(tree.pred, Purchase.test)
(110+56)/214
tree.Purchase = tree(Purchase ~ ., split = "gini", data = OJ, subset = train)
summary(tree.Purchase)
cv.tree(tree.Purchase, FUN = prune.misclass)
cv.oj = cv.tree(tree.Purchase, FUN = prune.misclass)
rm(cv.ok)
rm(cv.oj)
set.seed(0)
cv.purchase = cv.tree(tree.Purchase, FUN = prune.misclass)
cv.purchase
plot(cv.purchase$size, cv.purchase$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.purchase$k, cv.purchase$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations") #alpha is low allowing for more trees, as alpha grows, we go way to simple introducing bias
par(mfrow = c(1, 2))
plot(cv.purchase$size, cv.purchase$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.purchase$k, cv.purchase$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations") #alpha is low allowing for more trees, as alpha grows, we go way to simple introducing bias
prune.misclass(tree.Purchase, best = 16)
par(mfrow = c(1, 1))
prune.purchase = prune.misclass(tree.Purchase, best = 16)
plot(prune.purchase)
text(prune.purchase, pretty = 0)
predict(prune.purchase, Purchase.test, type = "class")
tree.pred = predict(prune.purchase, Purchase.test, type = "class")
table(tree.pred, Purchase.test)
length(tree.pred)
length(Purchase.test)
table(tree.pred, Purchase[train])
OJ.test
tree.Purchase
tree.pred = predict(prune.purchase, Purchase[train], type = "class")
table(tree.pred, Purchase.test)
tree.pred = predict(prune.purchase, Purchase[-train], type = "class")
table(tree.pred, Purchase.test)
tree.pred = predict(prune.purchase, OJ.test, type = "class")
table(tree.pred, Purchase.test)
(116 + 46)/(116 + 46 + 34 +18)
summary(tree.Purchase)
tree.pred.test = predict(prune.purchase, OJ[train, ], type = "class")
table(tree.pred.test, Purchase[train])
(470 + 236)/(470 + 236 + 101 +49)
library(randomForest)
set.seed(0)
rf.purchase = randomForest(Purchase ~ ., data = OJ[train, ], importance = TRUE)
rf.purchase
??randomForest
importance(rf.purchase)
varImpPlot(rf.purchase)
head(OJ)
set.seed(0)
oob.err = numeric(17)
for (mtry in 1:17) {
fit = randomForest(Purchase ~ ., data = OJ[train, ], mtry = mtry)
oob.err[mtry] = fit$err.rate[500, 1]#fit$mse[500]
cat("We're performing iteration", mtry, "\n")
}
plot(1:17, oob.err, pch = 16, type = "b",
xlab = "Variables Considered at Each Split",
ylab = "OOB Mean Squared Error",
main = "Random Forest OOB Error Rates\nby # of Variables")
Ames <-  geocode("Ames")
library(flexclust)
install.packages("flexclust")
data(nutrient)
library(flexclust)
data(nutrient)
nutrient
summary(nutrient)
sapply(nutrient, sd)
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
d = dist(nutrient.scaled)
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
?dist
clusters.average = cutree(fit.average, k = 5)
clusters.average
dist(nutrient.scaled)
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
clusters.average = cutree(fit.average, k = 5)
clusters.average
clusters.average = cutree(fit.single, k = 5)
clusters.average
clusters.average = cutree(fit.average, k = 5)
clusters.average
table(clusters.average)
aggregate(nutrient, by = list(cluster = clusters.average), median)
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
setwd("~/NYCDSA/Bootcamp/Lecture Slides/AssociationRules_NaiveBayes")
not.useful = read.csv("Groceries.csv", header = FALSE)
head(not.useful)
View(not.useful)
library(arules)
groceries = read.transactions("Groceries.csv", sep = ",")
install.packages("arules")
library(arules)
groceries = read.transactions("Groceries.csv", sep = ",")
class(groceries)
dim(groceries)
rownames(groceries)
colnames(groceries)
summary(groceries)
groceries = arules::read.transactions("Groceries.csv", sep = ",")
size(groceries)
hist(size(groceries))
inspect(groceries[1:10])
itemFrequency(groceries[, 1:5], type = "relative")
itemFrequency(groceries[, 1:5], type = "absolute")
hist(size(groceries),50)
#Using the itemFrequencyPlot() function to visualize item frequencies.
itemFrequencyPlot(groceries)
itemFrequencyPlot(groceries, support = 0.1)
itemFrequencyPlot(groceries, topN = 20)
itemFrequencyPlot(groceries)
itemFrequencyPlot(groceries, topN = 20)
itemFrequencyPlot(groceries, support = 0.1)
image(sample(groceries, 100))
groceryrules = apriori(groceries,
parameter = list(support = 0.006,
confidence = 0.25,
minlen = 2))
#Investigating summary information about the rule object.
groceryrules
class(groceryrules)
summary(groceryrules)
class(groceryrules)
inspect(groceryrules[1:5])
berryrules = subset(groceryrules, items %in% "berries")
inspect(berryrules)
herbrules = subset(groceryrules, items %in% "herbs")
inspect(herbrules)
setwd("~/NYCDSA/Bootcamp/Projects/Machine Learning/Data/DataScienceCaseStudy")
setwd("~/NYCDSA/Bootcamp/Projects/Machine Learning/Data/DataScienceCaseStudy")
setwd("~/NYCDSA/Bootcamp/Projects/Machine Learning/Data")
library(data.table)
library(dplyr)
library(ggplot2)
library(tidyr)
library(DT)
library(plotly)
library(ggrepel)
library(missForest)
subTrain = read.csv("train.csv",stringsAsFactors = FALSE)
subTest = read.csv("test.csv",stringsAsFactors = FALSE)
train = read.csv("train.csv",stringsAsFactors = FALSE)
test = read.csv("test.csv",stringsAsFactors = FALSE)
table(train$PavedDrive)
source('~/.active-rstudio-document', echo=TRUE)
summary(train$WoodDeckSF)
train %>% filter(.,PavedDrive) %>%  dplyr::group_by(.,PavedDrive) %>%
summarise(
count = n(),
mean = mean(PavedDrive, na.rm = TRUE),
sd = sd(PavedDrive, na.rm = TRUE)
)
train %>%
filter(.,train$PavedDrive) %>%
dplyr::group_by(.,train$PavedDrive) %>%
summarise(
count = n(),
mean = mean(PavedDrive, na.rm = TRUE),
sd = sd(PavedDrive, na.rm = TRUE))
train %>%
dplyr::group_by(.,train$PavedDrive) %>%
summarise(
count = n(),
mean = mean(PavedDrive, na.rm = TRUE),
sd = sd(PavedDrive, na.rm = TRUE))
train %>%
dplyr::group_by(.,train$PavedDrive) %>%
summarise(
count = n(),
mean = mean(SalePrice, na.rm = TRUE),
sd = sd(SalePrice, na.rm = TRUE))
res.aov <- aov(SalePrice ~ PavedDrive, data = train)
TukeyHSD(res.aov)
library(multcomp)
install.packages("multcomp")
library(multcomp)
summary(glht(res.aov, linfct = mcp(group = "Tukey")))
summary(glht(res.aov, linfct = mcp(PavedDrive = "Tukey")))
pairwise.t.test(train$SalePrice, train$PavedDrive,
p.adjust.method = "BH", pool.sd = FALSE)
TukeyHSD(res.aov)
pairwise.t.test(train$SalePrice, train$PavedDrive,p.adjust.method = "none")
res.aov <- aov(SalePrice ~ PavedDrive, data = train)
TukeyHSD(res.aov)
pairwise.t.test(train$SalePrice, train$PavedDrive
p.adjust.method = "BH", pool.sd = FALSE)
pairwise.t.test(train$SalePrice, train$PavedDrive,
p.adjust.method = "BH", pool.sd = FALSE)
res.aov <- aov(SalePrice ~ PavedDrive, data = train)
TukeyHSD(res.aov)
ggplot(train, aes(WoodDeckSF, fill = SalePrice)) +
geom_histogram(binwidth = 500)
ggplot(train, aes(WoodDeckSF)) +
geom_histogram(binwidth = 500)
summary(train$WoodDeckSF)
ggplot(train, aes(WoodDeckSF)) +
geom_histogram(binwidth = 50)
ggplot(train, aes(log(WoodDeckSF))) +
geom_histogram(binwidth = 50)
ggplot(train, aes(log(WoodDeckSF+1))) +
geom_histogram(binwidth = 50)
log(WoodDeckSF+1)
train$WoodDeckSF
train$WoodDeckSF+1
log(train$WoodDeckSF+1)
ggplot(train, aes(log(train$WoodDeckSF+1))) +
geom_histogram(binwidth = 50)
train %>% mutate(WoodDeckSF = log(WoodDeckSF+1))
ifelse(WoodDeckSF == 0, 'No', 'Yes')
train = train %>% mutate(hasDeck = ifelse(WoodDeckSF == 0, 'No', 'Yes'))
train = train %>% mutate(hasDeck = ifelse(WoodDeckSF == 0, 'No', 'Yes'))
ggplot(train, aes(log(train$WoodDeckSF+1))) +
geom_histogram(binwidth = 50)
summary(train$OpenPorchSF)
ggplot(train, aes(OpenPorchSF)) +
geom_histogram(binwidth = 50)
ggplot(train, aes(log(train$OpenPorchSF+1))) +
geom_histogram(binwidth = 50)
ggplot(train, aes(log(train$OpenPorchSF+1))) +
geom_histogram(binwidth = 5)
ggplot(train, aes(log(train$OpenPorchSF+1))) +
geom_histogram(binwidth = 2)
train = train %>% mutate(OpenPorchSF = log(OpenPorchSF+1))
train = train %>% mutate(hasOpenPorch = ifelse(OpenPorchSF == 0, 'No', 'Yes'))
head(train)
summary(train$EnclosedPorch)
train = train %>% mutate(EnclosedPorch = log(EnclosedPorch+1))
train = train %>% mutate(hasEnlosedPorch = ifelse(EnclosedPorch == 0, 'No', 'Yes'))
train
summary(train$3SsnPorch)
summary(train$X3SsnPorch)
train %>% mutate(X3SsnPorch = log(X3SsnPorch+1))
table(train$X3SsnPorch)
train = train %>% mutate(hasX3SsnPorch = ifelse(X3SsnPorch == 0, 'No', 'Yes'))
res.aov <- aov(SalePrice ~ hasX3SsnPorch, data = train)
TukeyHSD(res.aov)
res.aov <- aov(SalePrice ~ hasEnlosedPorch, data = train)
TukeyHSD(res.aov)
res.aov <- aov(SalePrice ~ hasOpenPorch, data = train)
TukeyHSD(res.aov)
train$X3SsnPorch=NULL
train
table(train$ScreenPorch)
train = train %>% mutate(hasScreenPorch = ifelse(ScreenPorch == 0, 'No', 'Yes'))
res.aov <- aov(SalePrice ~ hasScreenPorch, data = train)
TukeyHSD(res.aov)
train %>% mutate(ScreenPorch = log(ScreenPorch+1))
train = train %>% mutate(ScreenPorch = log(ScreenPorch+1))
summary(train$PoolArea)
summary(log(train$PoolArea+1))
ggplot(train, aes(PoolArea)) +
geom_histogram(binwidth = 50)
train$PoolArea=NULL
poolQc_converter = function(x, na.rm = TRUE){
if(is.na(x) == TRUE){
return(0)
} else if(x == 'Fa'){
return(1)
} else if(x == 'TA'){
return(2)
} else if(x == 'Gd'){
return(3)
} else if(x == 'Ex'){
return(4)
}
}
sapply(train$PoolQC, poolQc_converter)
poolQc_converter = function(x){
if(x == 'NA'){
return(0)
} else if(x == 'Fa'){
return(1)
} else if(x == 'TA'){
return(2)
} else if(x == 'Gd'){
return(3)
} else if(x == 'Ex'){
return(4)
}
}
sapply(train$PoolQC, poolQc_converter)
table(train$PoolQC)
poolQc_converter = function(x, na.rm = TRUE){
if(is.na(x) == TRUE){
return(0)
} else if(x == 'Fa'){
return(1)
} else if(x == 'TA'){
return(2)
} else if(x == 'Gd'){
return(3)
} else if(x == 'Ex'){
return(4)
}
}
hi = sapply(train$PoolQC, poolQc_converter)
table(hi)
train$PoolQC = sapply(train$PoolQC, poolQc_converter)
table(train$Fence)
ifelse(is.na(train$Fence),1,0)
table(train$PoolQC)
ifelse(train$PoolQC == 0 ,0,1)
train = train %>% mutate(hasPool = ifelse(train$PoolQC == 0 ,0,1))
train$PoolQC=NULL
table(train$Fence)
fence_converter = function(x, na.rm = TRUE){
if(is.na(x) == TRUE){
return(0)
} else if(x == 'MnWw'){
return(1)
} else if(x == 'GdWo'){
return(2)
} else if(x == 'MnPrv'){
return(3)
} else if(x == 'GdPrv'){
return(4)
}
}
train$Fence = sapply(train$Fence, fence_converter)
table(train$Fence)
table(train$Fence)
table(train$MiscFeature)
train$MiscFeature=NULL
table(train$Value)
table(train$MiscVal)
train = train %>% mutate(MiscVal = log(MiscVal+1))
ggplot(train, aes(MiscVal)) +
geom_histogram(binwidth = 2)
ggplot(train, aes(x = train$MoSold,y = train$SalePrice)) + geom_boxplot() + coord_flip()
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
stat_summary(fun.y = avg)
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
stat_summary(fun.y = 'median')
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
stat_summary(fun.y = 'average')
######Mo Sold############################################
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
stat_summary(fun.y = 'mean')
ggplot(train, aes(train$MoSold, train$SalePrice))+
geom_bar(stat="identity")
stat_summary(fun.y = 'mean')
ggplot(data= train) +
aes(x = train$MoSold,
y = train$SalePrice)+
stat_summary(fun.y=mean, geom="bar")
ggplot(data= train) +
aes(x = train$YrSold,
y = train$SalePrice)+
stat_summary(fun.y=mean, geom="bar")
ggplot(data= train) +
aes(x = train$YrSold,
y = train$SalePrice)+
stat_summary(aes(fill = factor(YrSold)),fun.y=mean, geom="bar")
table(train$SaleType)
train = train %>% mutate(SaleType = ifelse(SaleType %in% c('WD','CWD','VWD'), 'Warranty Deed',
ifelse(SaleType %in% c('New'), 'New Home',
ifelse(SaleType %in% c('COD'), 'Court Deed/Estate',
ifelse(SaleType %in% c('ConLD', 'ConLI','ConLw'), 'Low Interest/Down Payment',
ifelse(SaleType %in% c('Con'), 'Regular Terms', 'Other')))))
train = train %>% mutate(SaleType = ifelse(SaleType %in% c('WD','CWD','VWD'), 'Warranty Deed',
ifelse(SaleType %in% c('New'), 'New Home',
ifelse(SaleType %in% c('COD'), 'Court Deed/Estate',
ifelse(SaleType %in% c('ConLD', 'ConLI','ConLw'), 'Low Interest/Down Payment',
ifelse(SaleType %in% c('Con'), 'Regular Terms', 'Other'))))))
ggplot(train, aes(x = train$SaleCondition,y = train$SalePrice)) + geom_boxplot() + coord_flip()
paved_anova = train %>%
dplyr::group_by(.,train$SaleCondition) %>%
summarise(
count = n(),
mean = mean(SalePrice, na.rm = TRUE),
sd = sd(SalePrice, na.rm = TRUE))
res.aov <- aov(SalePrice ~ SaleCondition, data = train)
TukeyHSD(res.aov)
condition_anova = train %>%
dplyr::group_by(.,train$SaleCondition) %>%
summarise(
count = n(),
mean = mean(SalePrice, na.rm = TRUE),
sd = sd(SalePrice, na.rm = TRUE))
condition_anova
ggplot(train, aes(log(train$SalePrice+1))) +
geom_histogram(binwidth = 50)
ggplot(train, aes(train$SalePrice+1)) +
geom_histogram(binwidth = 50)
ggplot(train, aes(train$SalePrice)) +
geom_histogram(binwidth = 50)
ggplot(train, aes(train$SalePrice)) +
geom_histogram(binwidth = 10)
